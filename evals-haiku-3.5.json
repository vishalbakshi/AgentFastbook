[
  {
    "chapter": 4,
    "question_number": 2,
    "question_text": "\"How are the files and folders in the MNIST_SAMPLE dataset structured? Why?\"",
    "gold_standard_answer": "\"There are two subfolders, train and valid, the former contains the data for model training, the latter contains the data for validating model performance after each training step. Evaluating the model on the validation set serves two purposes: a) to report a human-interpretable metric such as accuracy (in contrast to the often abstract loss functions used for training), b) to facilitate the detection of overfitting by evaluating the model on a dataset it hasn\u2019t been trained on (in short, an overfitting model performs increasingly well on the training set but decreasingly so on the validation set). Of course, every practicioner could generate their own train/validation-split of the data. Public datasets are usually pre-split to simplifiy comparing results between implementations/publications.\n\nEach subfolder has two subsubfolders 3 and 7 which contain the .jpg files for the respective class of images. This is a common way of organizing datasets comprised of pictures. For the full MNIST dataset there are 10 subsubfolders, one for the images for each digit.\"",
    "ground_truth_components": [
      "There are two subfolders, train and valid, the former contains the data for model training, the latter contains the data for validating model performance after each training step",
      "Each subfolder has two subsubfolders 3 and 7",
      "which contain the .jpg files for the respective class of images",
      "Evaluating the model on the validation set",
      "facilitate the detection of overfitting by evaluating the model on a dataset it hasn\u2019t been trained on",
      "a) to report a human-interpretable metric such as accuracy (in contrast to the often abstract loss functions used for training)",
      "Public datasets are usually pre-split to simplifiy comparing results between implementations/publications",
      "For the full MNIST dataset there are 10 subsubfolders, one for the images for each digit"
    ],
    "haiku_components": [
      "There are two subfolders, train and valid",
      "the former contains the data for model training",
      "the latter contains the data for validating model performance after each training step",
      "Evaluating the model on the validation set serves two purposes: a) to report a human-interpretable metric such as accuracy (in contrast to the often abstract loss functions used for training)",
      "b) to facilitate the detection of overfitting by evaluating the model on a dataset it hasn't been trained on (in short, an overfitting model performs increasingly well on the training set but decreasingly so on the validation set)",
      "every practicioner could generate their own train/validation-split of the data",
      "Public datasets are usually pre-split to simplifiy comparing results between implementations/publications",
      "Each subfolder has two subsubfolders 3 and 7 which contain the .jpg files for the respective class of images",
      "This is a common way of organizing datasets comprised of pictures",
      "For the full MNIST dataset there are 10 subsubfolders, one for the images for each digit"
    ],
    "ground_truth_annotations": [
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        false,
        false,
        false,
        false,
        true,
        false,
        false,
        true
      ],
      "partial": [
        true,
        true,
        true,
        true,
        true,
        false,
        false,
        true,
        false,
        false
      ],
      "extra": [
        false,
        false,
        false,
        false,
        true,
        true,
        false,
        false,
        true,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    "notes": "Haiku does a more granular decomposition that me. For example \"There are two subfolders, train and valid, the former contains the data for model training, the latter contains the data for validating model performance after each training step\" is split into three components: \"There are two subfolders, train and valid\", \"the former contains the data for model training\", and \"the latter contains the data for validating model performance after each training step\". In another case, Haiku combines ground truth components that were separate: \"Evaluating the model on the validation set serves two purposes: a) to report a human-interpretable metric such as accuracy (in contrast to the often abstract loss functions used for training)\" (Haiku) is the combination of \" Evaluating the model on the validation set\" and \"a) to report a human-interpretable metric such as accuracy (in contrast to the often abstract loss functions used for training)\" (Human generated). Haiku also generates components that I did not: \"every practicioner could generate their own train/validation-split of the data\" and \"This is a common way of organizing datasets comprised of pictures\". I think that the extra components might have relevant passages from the text but I don't consider them important to the gold standard answer. On the other hand, there might not be relevant passages for those components and so they should be removed from the dataset.\n"
  },
  {
    "chapter": 4,
    "question_number": 3,
    "question_text": "\"Explain how the \"pixel similarity\" approach to classifying digits works.\"",
    "gold_standard_answer": "\"In the \u201cpixel similarity\u201d approach, we generate an archetype for each class we want to identify. In our case, we want to distinguish images of 3\u2019s from images of 7\u2019s. We define the archetypical 3 as the pixel-wise mean value of all 3\u2019s in the training set. Analoguously for the 7\u2019s. You can visualize the two archetypes and see that they are in fact blurred versions of the numbers they represent.\nIn order to tell if a previously unseen image is a 3 or a 7, we calculate its distance to the two archetypes (here: mean pixel-wise absolute difference). We say the new image is a 3 if its distance to the archetypical 3 is lower than two the archetypical 7.\"",
    "ground_truth_components": [
      "We define the archetypical 3 as the pixel-wise mean value of all 3\u2019s in the training set. Analoguously for the 7\u2019s. You can visualize the two archetypes and see that they are in fact blurred versions of the numbers they represent.\nIn order to tell if a previously unseen image is a 3 or a 7, we calculate its distance to the two archetypes (here: mean pixel-wise absolute difference). We say the new image is a 3 if its distance to the archetypical 3 is lower than two the archetypical 7"
    ],
    "haiku_components": [
      "\"In the \"pixel similarity\" approach, we generate an archetype for each class we want to identify.",
      "In our case, we want to distinguish images of 3's from images of 7's.",
      "We define the archetypical 3 as the pixel-wise mean value of all 3's in the training set.",
      "Analoguously for the 7's.",
      "You can visualize the two archetypes and see that they are in fact blurred versions of the numbers they represent.",
      "In order to tell if a previously unseen image is a 3 or a 7, we calculate its distance to the two archetypes (here: mean pixel-wise absolute difference).",
      "We say the new image is a 3 if its distance to the archetypical 3 is lower than two the archetypical 7."
    ],
    "ground_truth_annotations": [
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        false,
        false,
        false,
        false,
        false
      ],
      "partial": [
        false,
        false,
        true,
        true,
        true,
        true,
        true
      ],
      "extra": [
        true,
        true,
        false,
        false,
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    "notes": "Haiku has 7 components whereas I determined that the entire answer could be addressed with a single component. Haiku also generates two additional components which I think are actually useful to have. I did not consider \"\"In the \"pixel similarity\" approach, we generate an archetype for each class we want to identify.\" as a component while Haiku did---upon reflection this is a good summary of pixel similarity. The second extra component \"In our case, we want to distinguish images of 3's from images of 7's.\" is less important/informative but could help find relevant passages in the text. There are some components that are not fully structured sentences which I don't think will be useful for retrieval: \"Analoguously for the 7's.\". To be determined, but I would imagine that some of these components will retrieve the same relevant passages."
  },
  {
    "chapter": 4,
    "question_number": 4,
    "question_text": "\"What is a list comprehension? Create one now that selects odd numbers from a list and doubles them.\"",
    "gold_standard_answer": "\"Lists (arrays in other programming languages) are often generated using a for-loop. A list comprehension is a Pythonic way of condensing the creation of a list using a for-loop into a single expression. List comprehensions will also often include if clauses for filtering.\n\nlst_in = range(10)\nlst_out = [2*el for el in lst_in if el%2==1]\n# is equivalent to:\nlst_out = []\nfor el in lst_in:\n   if el%2==1:\n       lst_out.append(2*el)\"",
    "ground_truth_components": [
      "\"Lists (arrays in other programming languages) are often generated using a for-loop. A list comprehension is a Pythonic way of condensing the creation of a list using a for-loop into a single expression. List comprehensions will also often include if clauses for filtering.\n\nlst_in = range(10)\nlst_out = [2*el for el in lst_in if el%2==1]\n# is equivalent to:\nlst_out = []\nfor el in lst_in:\n   if el%2==1:\n       lst_out.append(2*el)\""
    ],
    "haiku_components": [
      "Lists (arrays in other programming languages) are often generated using a for-loop.",
      "A list comprehension is a Pythonic way of condensing the creation of a list using a for-loop into a single expression.",
      "List comprehensions will also often include if clauses for filtering."
    ],
    "ground_truth_annotations": [
      true
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        false
      ],
      "partial": [
        true,
        true,
        true
      ],
      "extra": [
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false
      ]
    },
    "notes": "Haiku does not generate components for the example code in the gold answer. Not sure if this is relevant for search as I'm not sure this example was in the text. The Haiku components do make sense in that they are unique concepts that each could potentially have their own relevant text."
  },
  {
    "chapter": 4,
    "question_number": 5,
    "question_text": "\"What is a \"rank-3 tensor\"?\"",
    "gold_standard_answer": "\"The rank of a tensor is the number of dimensions it has. An easy way to identify the rank is the number of indices you would need to reference a number within a tensor. A scalar can be represented as a tensor of rank 0 (no index), a vector can be represented as a tensor of rank 1 (one index, e.g., v[i]), a matrix can be represented as a tensor of rank 2 (two indices, e.g., a[i,j]), and a tensor of rank 3 is a cuboid or a \u201cstack of matrices\u201d (three indices, e.g., b[i,j,k]). In particular, the rank of a tensor is independent of its shape or dimensionality, e.g., a tensor of shape 2x2x2 and a tensor of shape 3x5x7 both have rank 3.\nNote that the term \u201crank\u201d has different meanings in the context of tensors and matrices (where it refers to the number of linearly independent column vectors).\"",
    "ground_truth_components": [
      "The rank of a tensor is the number of dimensions it has",
      "An easy way to identify the rank is the number of indices you would need to reference a number within a tensor",
      "A scalar can be represented as a tensor of rank 0 (no index), a vector can be represented as a tensor of rank 1 (one index, e.g., v[i]), a matrix can be represented as a tensor of rank 2 (two indices, e.g., a[i,j])",
      "and a tensor of rank 3 is a cuboid or a \u201cstack of matrices\u201d",
      "In particular, the rank of a tensor is independent of its shape or dimensionality, e.g., a tensor of shape 2x2x2 and a tensor of shape 3x5x7 both have rank 3",
      "Note that the term \u201crank\u201d has different meanings in the context of tensors and matrices (where it refers to the number of linearly independent column vectors)"
    ],
    "haiku_components": [
      "The rank of a tensor is the number of dimensions it has.",
      "An easy way to identify the rank is the number of indices you would need to reference a number within a tensor.",
      "A scalar can be represented as a tensor of rank 0 (no index)",
      "A vector can be represented as a tensor of rank 1 (one index, e.g., v[i])",
      "A matrix can be represented as a tensor of rank 2 (two indices, e.g., a[i,j])",
      "A tensor of rank 3 is a cuboid or a \"stack of matrices\" (three indices, e.g., b[i,j,k])",
      "The rank of a tensor is independent of its shape or dimensionality, e.g., a tensor of shape 2x2x2 and a tensor of shape 3x5x7 both have rank 3.",
      "The term \"rank\" has different meanings in the context of tensors and matrices (where it refers to the number of linearly independent column vectors)."
    ],
    "ground_truth_annotations": [
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "haiku_annotations": {
      "exact": [
        true,
        true,
        false,
        false,
        false,
        false,
        true,
        true
      ],
      "partial": [
        false,
        false,
        true,
        true,
        true,
        true,
        false,
        false
      ],
      "extra": [
        false,
        false,
        false,
        false,
        false,
        true,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    "notes": "Even though I have considered \"(three indices, e.g., b[i,j,k])\" in \"a tensor of rank 3 is a cuboid or a \u201cstack of matrices\u201d (three indices, e.g., b[i,j,k]).\" as an \"extra component\" (I didn't include that in my answer component) I now think that Haiku is actually correct in including that because I did include \"(one index, e.g., v[i])\" in the rank 1 example as well as the rank 0 and rank 2 examples."
  },
  {
    "chapter": 4,
    "question_number": 6,
    "question_text": "\"What is the difference between tensor rank and shape? How do you get the rank from the shape?\"",
    "gold_standard_answer": "\"Rank is the number of axes or dimensions in a tensor; shape is the size of each axis of a tensor.\n\nThe length of a tensor\u2019s shape is its rank.\n\nSo if we have the images of the 3 folder from the MINST_SAMPLE dataset in a tensor called stacked_threes and we find its shape like this.\n\nIn [ ]: stacked_threes.shape\nOut[ ]: torch.Size([6131, 28, 28])\nWe just need to find its length to know its rank. This is done as follows.\n\nIn [ ]: len(stacked_threes.shape)\nOut[ ]: 3\nYou can also get a tensor\u2019s rank directly with ndim .\n\nIn [ ]: stacked_threes.ndim\nOut[ ]: 3\"",
    "ground_truth_components": [
      "Rank is the number of axes or dimensions in a tensor",
      "shape is the size of each axis of a tensor",
      "The length of a tensor\u2019s shape is its rank",
      "So if we have the images of the 3 folder from the MINST_SAMPLE dataset in a tensor called stacked_threes and we find its shape like this.\n\nIn [ ]: stacked_threes.shape\nOut[ ]: torch.Size([6131, 28, 28])\n\"",
      "In [ ]: stacked_threes.ndim\nOut[ ]: 3",
      "You can also get a tensor\u2019s rank directly with ndim"
    ],
    "haiku_components": [
      "Rank is the number of axes or dimensions in a tensor;",
      "shape is the size of each axis of a tensor.",
      "The length of a tensor's shape is its rank.",
      "So if we have the images of the 3 folder from the MINST_SAMPLE dataset in a tensor called stacked_threes and we find its shape like this.",
      "We just need to find its length to know its rank. This is done as follows.",
      "You can also get a tensor's rank directly with ndim ."
    ],
    "ground_truth_annotations": [
      false,
      false,
      false,
      true,
      true,
      false
    ],
    "haiku_annotations": {
      "exact": [
        true,
        true,
        true,
        false,
        false,
        true
      ],
      "partial": [
        false,
        false,
        false,
        true,
        false,
        false
      ],
      "extra": [
        false,
        false,
        false,
        false,
        true,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    "notes": "I flagged \"We just need to find its length to know its rank\" as an extra component but now I can see that it actually is a good summary of the answer and might be helpful in retrieving passages. Haiku doesn't include \"In [ ]: stacked_threes.shape Out[ ]: torch.Size([6131, 28, 28]) \" in the corresponding component which I'm not sure if it will be useful text for search. Same goes for my component\" In [ ]: stacked_threes.ndim Out[ ]: 3\" that Haiku did not generate."
  },
  {
    "chapter": 4,
    "question_number": 7,
    "question_text": "\"What are RMSE and L1 norm?\"",
    "gold_standard_answer": "\"Root mean square error (RMSE), also called the L2 norm, and mean absolute difference (MAE), also called the L1 norm, are two commonly used methods of measuring \u201cdistance\u201d. Simple differences do not work because some difference are positive and others are negative, canceling each other out. Therefore, a function that focuses on the magnitudes of the differences is needed to properly measure distances. The simplest would be to add the absolute values of the differences, which is what MAE is. RMSE takes the mean of the square (makes everything positive) and then takes the square root (undoes squaring).\"",
    "ground_truth_components": [
      [
        "Root mean square error (RMSE), also called the L2 norm, and mean absolute difference (MAE), also called the L1 norm",
        "The simplest would be to add the absolute values of the differences, which is what MAE is. RMSE takes the mean of the square (makes everything positive) and then takes the square root (undoes squaring)."
      ],
      "two commonly used methods of measuring \u201cdistance\u201d",
      "Simple differences do not work because some difference are positive and others are negative, canceling each other out. Therefore, a function that focuses on the magnitudes of the differences is needed to properly measure distances"
    ],
    "haiku_components": [
      "Root mean square error (RMSE), also called the L2 norm",
      "mean absolute difference (MAE), also called the L1 norm",
      "two commonly used methods of measuring \"distance\"",
      "Simple differences do not work because some difference are positive and others are negative, canceling each other out",
      "a function that focuses on the magnitudes of the differences is needed to properly measure distances",
      "The simplest would be to add the absolute values of the differences, which is what MAE is",
      "RMSE takes the mean of the square (makes everything positive) and then takes the square root (undoes squaring)"
    ],
    "ground_truth_annotations": [
      false,
      false,
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        true,
        false,
        false,
        false,
        false
      ],
      "partial": [
        true,
        true,
        false,
        true,
        true,
        true,
        true
      ],
      "extra": [
        false,
        false,
        false,
        false,
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    "notes": "Without knowing relevant passages, Haiku has done a good job of decomposing the answer into unique components. \"Root mean square error (RMSE), also called the L2 norm\", \"mean absolute difference (MAE), also called the L1 norm\", \"The simplest would be to add the absolute values of the differences, which is what MAE is\", and \"RMSE takes the mean of the square (makes everything positive) and then takes the square root (undoes squaring)\" are indeed unique self-contained ideas that I had grouped into a single component probably because the relevant passage contained all that information together.\n\nTODO: my first ground truth component is actually a list of two components. Not sure if I'll keep this as is."
  },
  {
    "chapter": 4,
    "question_number": 8,
    "question_text": "\"How can you apply a calculation on thousands of numbers at once, many thousands of times faster than a Python loop?\"",
    "gold_standard_answer": "\"As loops are very slow in Python, it is best to represent the operations as array operations rather than looping through individual elements. If this can be done, then using NumPy or PyTorch will be thousands of times faster, as they use underlying C code which is much faster than pure Python. Even better, PyTorch allows you to run operations on GPU, which will have significant speedup if there are parallel operations that can be done.\"",
    "ground_truth_components": [
      "As loops are very slow in Python, it is best to represent the operations as array operations rather than looping through individual elements. If this can be done, then using NumPy or PyTorch will be thousands of times faster, as they use underlying C code which is much faster than pure Python",
      "Even better, PyTorch allows you to run operations on GPU, which will have significant speedup if there are parallel operations that can be done"
    ],
    "haiku_components": [
      "loops are very slow in Python",
      "represent the operations as array operations rather than looping through individual elements",
      "using NumPy or PyTorch will be thousands of times faster",
      "they use underlying C code which is much faster than pure Python",
      "PyTorch allows you to run operations on GPU",
      "GPU operations will have significant speedup if there are parallel operations that can be done"
    ],
    "ground_truth_annotations": [
      false,
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        false,
        false,
        false,
        false
      ],
      "partial": [
        true,
        true,
        true,
        true,
        true,
        true
      ],
      "extra": [
        false,
        false,
        false,
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false,
        false,
        true
      ]
    },
    "notes": "I think I should have decomposed my first ground truth component \"As loops are very slow in Python, it is best to represent the operations as array operations rather than looping through individual elements. If this can be done, then using NumPy or PyTorch will be thousands of times faster, as they use underlying C code which is much faster than pure Python\" into two components \"As loops are very slow in Python, it is best to represent the operations as array operations rather than looping through individual elements. If this can be done, then using NumPy or PyTorch will be thousands of times faster,\" and \"as they use underlying C code which is much faster than pure Python\" because there are two unique relevant passages in the text that match each one separately. Looking at the relevant passages, you could even break these down further since \"loops are very slow in Python\" is itself a chunk in the text. In summary, Haiku's decomposition might actually better match the relevant text."
  },
  {
    "chapter": 4,
    "question_number": 10,
    "question_text": "\"What is broadcasting?\"",
    "gold_standard_answer": "\"Scientific/numerical Python packages like NumPy and PyTorch will often implement broadcasting that often makes code easier to write. In the case of PyTorch, tensors with smaller rank are expanded to have the same size as the larger rank tensor. In this way, operations can be performed between tensors with different rank.\"",
    "ground_truth_components": [
      "\"Scientific/numerical Python packages like NumPy and PyTorch will often implement broadcasting that often makes code easier to write. In the case of PyTorch, tensors with smaller rank are expanded to have the same size as the larger rank tensor. In this way, operations can be performed between tensors with different rank.\""
    ],
    "haiku_components": [
      "Scientific/numerical Python packages like NumPy and PyTorch",
      "broadcasting",
      "broadcasting often makes code easier to write",
      "In the case of PyTorch, tensors with smaller rank are expanded to have the same size as the larger rank tensor",
      "operations can be performed between tensors with different rank"
    ],
    "ground_truth_annotations": [
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        false,
        false,
        false
      ],
      "partial": [
        true,
        true,
        true,
        true,
        true
      ],
      "extra": [
        false,
        false,
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false,
        false
      ]
    },
    "notes": "Some of the Haiku answer components are too granular in that they mean something else out of context: \"Scientific/numerical Python packages like NumPy and PyTorch\" could mean any number of things not necessarily broadcasting related. \"broadcasting\" as an answer component is like a keyword. These two are more implicitly related to broadcasting than explicitly related: \"In the case of PyTorch, tensors with smaller rank are expanded to have the same size as the larger rank tensor\", and \"operations can be performed between tensors with different rank\""
  },
  {
    "chapter": 4,
    "question_number": 11,
    "question_text": "\"Are metrics generally calculated using the training set, or the validation set? Why?\"",
    "gold_standard_answer": "\"Metrics are generally calculated on a validation set. As the validation set is unseen data for the model, evaluating the metrics on the validation set is better in order to determine if there is any overfitting and how well the model might generalize if given similar data.\"",
    "ground_truth_components": [
      "Metrics are generally calculated on a validation set",
      "As the validation set is unseen data for the model, evaluating the metrics on the validation set is better in order to determine if there is any overfitting",
      "how well the model might generalize if given similar data"
    ],
    "haiku_components": [
      "Metrics are generally calculated on a validation set.",
      "As the validation set is unseen data for the model, evaluating the metrics on the validation set is better in order to determine if there is any overfitting",
      "and how well the model might generalize if given similar data."
    ],
    "ground_truth_annotations": [
      false,
      false,
      false
    ],
    "haiku_annotations": {
      "exact": [
        true,
        true,
        true
      ],
      "partial": [
        false,
        false,
        false
      ],
      "extra": [
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false
      ]
    },
    "notes": "Exact match, no comments."
  },
  {
    "chapter": 4,
    "question_number": 12,
    "question_text": "\"What is SGD?\"",
    "gold_standard_answer": "\"SGD, or stochastic gradient descent, is an optimization algorithm. Specifically, SGD is an algorithm that will update the parameters of a model in order to minimize a given loss function that was evaluated on the predictions and target. The key idea behind SGD (and many optimization algorithms, for that matter) is that the gradient of the loss function provides an indication of how that loss function changes in the parameter space, which we can use to determine how best to update the parameters in order to minimize the loss function. This is what SGD does.\"",
    "ground_truth_components": [
      "SGD, or stochastic gradient descent,",
      "optimization algorithm",
      "SGD is an algorithm that will update the parameters of a model",
      "in order to minimize a given loss function that was evaluated on the predictions and target",
      "The key idea behind SGD (and many optimization algorithms, for that matter) is that the gradient of the loss function provides an indication of how that loss function changes in the parameter space, which we can use to determine how best to update the parameters in order to minimize the loss function"
    ],
    "haiku_components": [
      "SGD, or stochastic gradient descent, is an optimization algorithm.",
      "SGD is an algorithm that will update the parameters of a model in order to minimize a given loss function that was evaluated on the predictions and target.",
      "The key idea behind SGD (and many optimization algorithms, for that matter) is that the gradient of the loss function provides an indication of how that loss function changes in the parameter space, which we can use to determine how best to update the parameters in order to minimize the loss function.",
      "This is what SGD does."
    ],
    "ground_truth_annotations": [
      false,
      false,
      false,
      false,
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        true,
        false
      ],
      "partial": [
        true,
        true,
        false,
        false
      ],
      "extra": [
        false,
        false,
        false,
        true
      ],
      "hallucination": [
        false,
        false,
        false,
        false
      ]
    },
    "notes": "\"This is what SGD does.\" is not a useful Haiku-generated answer component without more context. Haiku combines two pairs of ground truth components to create two longer components. TBD if this yields any issues in terms of retrieval. \"optimization algorithm\" didn't have any hits in the chapter text in relation to SGD so including it may not influence the retrieval."
  },
  {
    "chapter": 4,
    "question_number": 13,
    "question_text": "\"Why does SGD use mini-batches?\"",
    "gold_standard_answer": "\"We need to calculate our loss function (and our gradient) on one or more data points. We cannot calculate on the whole datasets due to compute limitations and time constraints. If we iterated through each data point, however, the gradient will be unstable and imprecise, and is not suitable for training. As a compromise, we calculate the average loss for a small subset of the dataset at a time. This subset is called a mini-batch. Using mini-batches are also more computationally efficient than single items on a GPU.\"",
    "ground_truth_components": [
      "We need to calculate our loss function (and our gradient) on one or more data points. We cannot calculate on the whole datasets due to compute limitations and time constraints. If we iterated through each data point, however, the gradient will be unstable and imprecise, and is not suitable for training",
      "As a compromise, we calculate the average loss for a small subset of the dataset at a time. This subset is called a mini-batch",
      "Using mini-batches are also more computationally efficient than single items on a GPU"
    ],
    "haiku_components": [
      "We need to calculate our loss function (and our gradient) on one or more data points.",
      "We cannot calculate on the whole datasets due to compute limitations and time constraints.",
      "If we iterated through each data point, however, the gradient will be unstable and imprecise, and is not suitable for training.",
      "As a compromise, we calculate the average loss for a small subset of the dataset at a time.",
      "This subset is called a mini-batch.",
      "Using mini-batches are also more computationally efficient than single items on a GPU."
    ],
    "ground_truth_annotations": [
      false,
      false,
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        false,
        false,
        false,
        true
      ],
      "partial": [
        true,
        true,
        true,
        true,
        true,
        false
      ],
      "extra": [
        false,
        false,
        false,
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    "notes": "Haiku components 1, 2 and 3 combined are the same as my ground truth component 1. I combined those concepts into one component because the chapter text relevant to all three was in one paragraph. I think I could split \"We need to calculate our loss function (and our gradient) on one or more data points. We cannot calculate on the whole datasets due to compute limitations and time constraints. If we iterated through each data point, however, the gradient will be unstable and imprecise, and is not suitable for training\" into the three parts that Haiku has generated as each part has one or more sentences in the text relevant to it. Haiku's granular decomposition matches the chapter text."
  },
  {
    "chapter": 4,
    "question_number": 14,
    "question_text": "\"What are the seven steps in SGD for machine learning?\"",
    "gold_standard_answer": "\"Initialize the parameters \u2013 Random values often work best.\nCalculate the predictions \u2013 This is done on the training set, one mini-batch at a time.\nCalculate the loss \u2013 The average loss over the minibatch is calculated\nCalculate the gradients \u2013 this is an approximation of how the parameters need to change in order to minimize the loss function\nStep the weights \u2013 update the parameters based on the calculated weights\nRepeat the process\nStop \u2013 In practice, this is either based on time constraints or usually based on when the training/validation losses and metrics stop improving.\"",
    "ground_truth_components": [
      "\"Initialize the parameters \u2013 Random values often work best.\nCalculate the predictions \u2013 This is done on the training set, one mini-batch at a time.\nCalculate the loss \u2013 The average loss over the minibatch is calculated\nCalculate the gradients \u2013 this is an approximation of how the parameters need to change in order to minimize the loss function\nStep the weights \u2013 update the parameters based on the calculated weights\nRepeat the process\nStop \u2013 In practice, this is either based on time constraints or usually based on when the training/validation losses and metrics stop improving.\"",
      "\"Initialize the parameters \u2013 Random values often work best.\nCalculate the predictions \u2013 This is done on the training set, one mini-batch at a time.\nCalculate the loss \u2013 The average loss over the minibatch is calculated\nCalculate the gradients \u2013 this is an approximation of how the parameters need to change in order to minimize the loss function\nStep the weights \u2013 update the parameters based on the calculated weights\nRepeat the process\nStop \u2013 In practice, this is either based on time constraints or usually based on when the training/validation losses and metrics stop improving.\""
    ],
    "haiku_components": [
      "Initialize the parameters \u2013 Random values often work best.",
      "Calculate the predictions \u2013 This is done on the training set, one mini-batch at a time.",
      "Calculate the loss \u2013 The average loss over the minibatch is calculated",
      "Calculate the gradients \u2013 this is an approximation of how the parameters need to change in order to minimize the loss function",
      "Step the weights \u2013 update the parameters based on the calculated weights",
      "Repeat the process",
      "Stop \u2013 In practice, this is either based on time constraints or usually based on when the training/validation losses and metrics stop improving."
    ],
    "ground_truth_annotations": [
      false,
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        false,
        false,
        false,
        false,
        false
      ],
      "partial": [
        true,
        true,
        true,
        true,
        true,
        true,
        true
      ],
      "extra": [
        false,
        false,
        false,
        false,
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    "notes": "TODO: combine the context for my repeated ground truth components in the existing dataset. \n\nThis is another scenario where Haiku's granularity will match up 1:1 to each sentence or bullet point in the chapter text relevant to this answer."
  },
  {
    "chapter": 4,
    "question_number": 15,
    "question_text": "\"How do we initialize the weights in a model?\"",
    "gold_standard_answer": "\"Random weights work pretty well.\"",
    "ground_truth_components": [
      "\"Random weights work pretty well.\""
    ],
    "haiku_components": [
      "\"Random weights\"",
      "\"work pretty well\""
    ],
    "ground_truth_annotations": [
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false
      ],
      "partial": [
        true,
        true
      ],
      "extra": [
        false,
        false
      ],
      "hallucination": [
        false,
        false
      ]
    },
    "notes": "\"work pretty well\" is a Haiku component that doesn't make sense out of context. Too granular."
  },
  {
    "chapter": 4,
    "question_number": 16,
    "question_text": "\"What is \"loss\"?\"",
    "gold_standard_answer": "\"The loss function will return a value based on the given predictions and targets, where lower values correspond to better model predictions.\"",
    "ground_truth_components": [
      "The loss function will return a value based on the given predictions and targets",
      "lower values correspond to better model predictions"
    ],
    "haiku_components": [
      "The loss function",
      "will return a value",
      "based on the given predictions and targets",
      "lower values correspond to better model predictions"
    ],
    "ground_truth_annotations": [
      false,
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        false,
        true
      ],
      "partial": [
        true,
        true,
        true,
        false
      ],
      "extra": [
        false,
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false
      ]
    },
    "notes": "Not sure how granularity will affect retrieval. \"will return a value\" as a Haiku component probably doesn't make sense out of context on its own."
  },
  {
    "chapter": 4,
    "question_number": 17,
    "question_text": "\"Why can't we always use a high learning rate?\"",
    "gold_standard_answer": "\"The loss may \u201cbounce\u201d around (oscillate) or even diverge, as the optimizer is taking steps that are too large, and updating the parameters faster than it should be.\"",
    "ground_truth_components": [
      "or even diverge",
      "The loss may \u201cbounce\u201d around (oscillate)",
      "the optimizer is taking steps that are too large, and updating the parameters faster than it should be"
    ],
    "haiku_components": [
      "\"The loss may \"bounce\" around (oscillate)\"",
      "\"or even diverge\"",
      "\"as the optimizer is taking steps that are too large\"",
      "\"and updating the parameters faster than it should be.\""
    ],
    "ground_truth_annotations": [
      false,
      false,
      false
    ],
    "haiku_annotations": {
      "exact": [
        true,
        true,
        false,
        false
      ],
      "partial": [
        false,
        false,
        true,
        true
      ],
      "extra": [
        false,
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false
      ]
    },
    "notes": "My ground truth component \"or even diverge\" might not make sense out of context (although it may work for a keyword search). TBD if Haiku granular components work for retrieval."
  },
  {
    "chapter": 4,
    "question_number": 18,
    "question_text": "\"What is a \"gradient\"?\"",
    "gold_standard_answer": "\"The gradients tell us how much we have to change each weight to make our model better. It is essentially a measure of how the loss function changes with changes of the weights of the model (the derivative).\"",
    "ground_truth_components": [
      "The gradients tell us how much we have to change each weight to make our model better",
      "It is essentially a measure of how the loss function changes with changes of the weights of the model (the derivative)"
    ],
    "haiku_components": [
      "The gradients tell us how much we have to change each weight to make our model better.",
      "It is essentially a measure of how the loss function changes with changes of the weights of the model (the derivative)."
    ],
    "ground_truth_annotations": [
      false,
      false
    ],
    "haiku_annotations": {
      "exact": [
        true,
        true
      ],
      "partial": [
        false,
        false
      ],
      "extra": [
        false,
        false
      ],
      "hallucination": [
        false,
        false
      ]
    },
    "notes": "Exact match, no comments."
  },
  {
    "chapter": 4,
    "question_number": 19,
    "question_text": "\"Do you need to know how to calculate gradients yourself?\"",
    "gold_standard_answer": "\"Manual calculation of the gradients are not required, as deep learning libraries will automatically calculate the gradients for you. This feature is known as automatic differentiation. In PyTorch, if requires_grad=True, the gradients can be returned by calling the backward method: a.backward()\"",
    "ground_truth_components": [
      "Manual calculation of the gradients are not required, as deep learning libraries will automatically calculate the gradients for you",
      "In PyTorch, if requires_grad=True, the gradients can be returned by calling the backward method: a.backward()",
      "This feature is known as automatic differentiation"
    ],
    "haiku_components": [
      "Manual calculation of the gradients are not required",
      "deep learning libraries will automatically calculate the gradients for you",
      "This feature is known as automatic differentiation",
      "In PyTorch, if requires_grad=True, the gradients can be returned by calling the backward method: a.backward()"
    ],
    "ground_truth_annotations": [
      false,
      false,
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        true,
        true
      ],
      "partial": [
        true,
        true,
        false,
        false
      ],
      "extra": [
        false,
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false
      ]
    },
    "notes": "Chapter context contains separate sentences corresponding to each of the Haiku partial match components so it should be okay to keep them more granular than mine."
  },
  {
    "chapter": 4,
    "question_number": 20,
    "question_text": "\"Why can't we use accuracy as a loss function?\"",
    "gold_standard_answer": "\"A loss function needs to change as the weights are being adjusted. Accuracy only changes if the predictions of the model change. So if there are slight changes to the model that, say, improves confidence in a prediction, but does not change the prediction, the accuracy will still not change. Therefore, the gradients will be zero everywhere except when the actual predictions change. The model therefore cannot learn from the gradients equal to zero, and the model\u2019s weights will not update and will not train. A good loss function gives a slightly better loss when the model gives slightly better predictions. Slightly better predictions mean if the model is more confident about the correct prediction. For example, predicting 0.9 vs 0.7 for probability that a MNIST image is a 3 would be slightly better prediction. The loss function needs to reflect that.\"",
    "ground_truth_components": [
      "A loss function needs to change as the weights are being adjusted",
      "Accuracy only changes if the predictions of the model change. So if there are slight changes to the model that, say, improves confidence in a prediction, but does not change the prediction, the accuracy will still not change. Therefore, the gradients will be zero everywhere except when the actual predictions change",
      "The model therefore cannot learn from the gradients equal to zero, and the model\u2019s weights will not update and will not train",
      "A good loss function gives a slightly better loss when the model gives slightly better predictions",
      "Slightly better predictions mean if the model is more confident about the correct prediction"
    ],
    "haiku_components": [
      "A loss function needs to change as the weights are being adjusted.",
      "Accuracy only changes if the predictions of the model change.",
      "If there are slight changes to the model that, say, improves confidence in a prediction, but does not change the prediction, the accuracy will still not change.",
      "The gradients will be zero everywhere except when the actual predictions change.",
      "The model cannot learn from the gradients equal to zero, and the model's weights will not update and will not train.",
      "A good loss function gives a slightly better loss when the model gives slightly better predictions.",
      "Slightly better predictions mean if the model is more confident about the correct prediction.",
      "For example, predicting 0.9 vs 0.7 for probability that a MNIST image is a 3 would be slightly better prediction.",
      "The loss function needs to reflect that."
    ],
    "ground_truth_annotations": [
      false,
      false,
      false,
      false,
      false
    ],
    "haiku_annotations": {
      "exact": [
        true,
        false,
        false,
        false,
        true,
        true,
        true,
        false,
        false
      ],
      "partial": [
        false,
        true,
        true,
        true,
        false,
        false,
        false,
        false,
        false
      ],
      "extra": [
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        true,
        true
      ],
      "hallucination": [
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    "notes": "Looking at the extra components: \"The loss function needs to reflect that.\" Haiku component doesn't make sense out of context. \"For example, predicting 0.9 vs 0.7 for probability that a MNIST image is a 3 would be slightly better prediction.\" is not really found in the chapter text.  For the partial matches, separate sentences in the chapter text match the separate Haiku components."
  },
  {
    "chapter": 4,
    "question_number": 22,
    "question_text": "\"What is the difference between a loss function and a metric?\"",
    "gold_standard_answer": "\"The key difference is that metrics drive human understanding and losses drive automated learning. In order for loss to be useful for training, it needs to have a meaningful derivative. Many metrics, like accuracy are not like that. Metrics instead are the numbers that humans care about, that reflect the performance of the model.\"",
    "ground_truth_components": [
      "\"The key difference is that metrics drive human understanding and losses drive automated learning. In order for loss to be useful for training, it needs to have a meaningful derivative. Many metrics, like accuracy are not like that. Metrics instead are the numbers that humans care about, that reflect the performance of the model.\""
    ],
    "haiku_components": [
      "The key difference is that metrics drive human understanding",
      "losses drive automated learning",
      "In order for loss to be useful for training, it needs to have a meaningful derivative",
      "Many metrics, like accuracy are not like that",
      "Metrics instead are the numbers that humans care about, that reflect the performance of the model"
    ],
    "ground_truth_annotations": [
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        false,
        false,
        false
      ],
      "partial": [
        true,
        true,
        true,
        true,
        true
      ],
      "extra": [
        false,
        false,
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false,
        false
      ]
    },
    "notes": "For the Haiku components \"losses drive automated learning\" and \"In order for loss to be useful for training, it needs to have a meaningful derivative\" the chapter text relevant to them is a single sentence which might lead to redundant retrieval results (best case) or each component on its own is not enough context to find that single sentence (worst case). TBD how this works out during retrieval.\n\nTODO: \"Metrics instead are the numbers that humans care about, that reflect the performance of the model\" Haiku component is not addressed by the gold relevant context in the dataset. Might need to add context for that component. This is an example where Haiku-generated components inform me about gaps in my current dataset."
  },
  {
    "chapter": 4,
    "question_number": 23,
    "question_text": "\"What is the function to calculate new weights using a learning rate?\"",
    "gold_standard_answer": "\"The optimizer step function\"",
    "ground_truth_components": [
      "\"The optimizer step function\""
    ],
    "haiku_components": [
      "The optimizer step function"
    ],
    "ground_truth_annotations": [
      false
    ],
    "haiku_annotations": {
      "exact": [
        true
      ],
      "partial": [
        false
      ],
      "extra": [
        false
      ],
      "hallucination": [
        false
      ]
    },
    "notes": "Exact match, no comments."
  },
  {
    "chapter": 4,
    "question_number": 24,
    "question_text": "\"What does the DataLoader class do?\"",
    "gold_standard_answer": "\"The DataLoader class can take any Python collection and turn it into an iterator over many batches.\"",
    "ground_truth_components": [
      "\"The DataLoader class can take any Python collection and turn it into an iterator over many batches.\""
    ],
    "haiku_components": [
      "The DataLoader class",
      "can take any Python collection",
      "turn it into an iterator over many batches"
    ],
    "ground_truth_annotations": [
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        false
      ],
      "partial": [
        true,
        true,
        true
      ],
      "extra": [
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false
      ]
    },
    "notes": "Even though Haiku has split my ground truth component into three separate ones, each one might act as a keyword during search. TBD how this works out during retrieval."
  },
  {
    "chapter": 4,
    "question_number": 27,
    "question_text": "\"What does view do in PyTorch?\"",
    "gold_standard_answer": "\"It changes the shape of a Tensor without changing its contents.\"",
    "ground_truth_components": [
      "\"It changes the shape of a Tensor without changing its contents.\""
    ],
    "haiku_components": [
      "It changes the shape of a Tensor",
      "without changing its contents"
    ],
    "ground_truth_annotations": [
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false
      ],
      "partial": [
        true,
        true
      ],
      "extra": [
        false,
        false
      ],
      "hallucination": [
        false,
        false
      ]
    },
    "notes": "\"without changing its contents\" Haiku component might not make sense out of context."
  },
  {
    "chapter": 4,
    "question_number": 28,
    "question_text": "\"What are the \"bias\" parameters in a neural network? Why do we need them?\"",
    "gold_standard_answer": "\"Without the bias parameters, if the input is zero, the output will always be zero. Therefore, using bias parameters adds additional flexibility to the model.\"",
    "ground_truth_components": [
      "\"Without the bias parameters, if the input is zero, the output will always be zero. Therefore, using bias parameters adds additional flexibility to the model.\""
    ],
    "haiku_components": [
      "Without the bias parameters, if the input is zero, the output will always be zero.",
      "Therefore, using bias parameters adds additional flexibility to the model."
    ],
    "ground_truth_annotations": [
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false
      ],
      "partial": [
        true,
        true
      ],
      "extra": [
        false,
        false
      ],
      "hallucination": [
        false,
        false
      ]
    },
    "notes": "This is another example where two granular components will best case retrieve the same context or worst case will not be sufficient to retrieve the single sentence gold context for this answer."
  },
  {
    "chapter": 4,
    "question_number": 29,
    "question_text": "\"What does the @ operator do in Python?\"",
    "gold_standard_answer": "\"This is the matrix multiplication operator.\"",
    "ground_truth_components": [
      "\"This is the matrix multiplication operator.\""
    ],
    "haiku_components": [
      "This is the matrix multiplication operator."
    ],
    "ground_truth_annotations": [
      false
    ],
    "haiku_annotations": {
      "exact": [
        true
      ],
      "partial": [
        false
      ],
      "extra": [
        false
      ],
      "hallucination": [
        false
      ]
    },
    "notes": "Exact match, no comments."
  },
  {
    "chapter": 4,
    "question_number": 30,
    "question_text": "\"What does the backward method do?\"",
    "gold_standard_answer": "\"This method returns the current gradients.\"",
    "ground_truth_components": [
      "\"This method returns the current gradients.\""
    ],
    "haiku_components": [
      "This method",
      "returns",
      "the current gradients"
    ],
    "ground_truth_annotations": [
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        false
      ],
      "partial": [
        true,
        true,
        true
      ],
      "extra": [
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false
      ]
    },
    "notes": "Two of the Haiku components \"returns\" and \"This method\" are likely too granular out of context. \"The current gradients\" is the strongest match for the gold context."
  },
  {
    "chapter": 4,
    "question_number": 31,
    "question_text": "\"Why do we have to zero the gradients?\"",
    "gold_standard_answer": "\"PyTorch will add the gradients of a variable to any previously stored gradients. If the training loop function is called multiple times, without zeroing the gradients, the gradient of current loss would be added to the previously stored gradient value.\"",
    "ground_truth_components": [
      "PyTorch will add the gradients of a variable to any previously stored gradients. If the training loop function is called multiple times, without zeroing the gradients, the gradient of current loss would be added to the previously stored gradient value"
    ],
    "haiku_components": [
      "PyTorch will add the gradients of a variable to any previously stored gradients.",
      "If the training loop function is called multiple times, without zeroing the gradients, the gradient of current loss would be added to the previously stored gradient value."
    ],
    "ground_truth_annotations": [
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false
      ],
      "partial": [
        true,
        true
      ],
      "extra": [
        false,
        false
      ],
      "hallucination": [
        false,
        false
      ]
    },
    "notes": "TODO: dataset currently doesn't contain context explicitly addressing \"If the training loop function is called multiple times, without zeroing the gradients, the gradient of current loss would be added to the previously stored gradient value.\". TBD if chapter text contains relevant context."
  },
  {
    "chapter": 4,
    "question_number": 32,
    "question_text": "\"What information do we have to pass to Learner?\"",
    "gold_standard_answer": "\"We need to pass in the DataLoaders, the model, the optimization function, the loss function, and optionally any metrics to print.\"",
    "ground_truth_components": [
      "\"We need to pass in the DataLoaders, the model, the optimization function, the loss function, and optionally any metrics to print.\""
    ],
    "haiku_components": [
      "DataLoaders",
      "model",
      "optimization function",
      "loss function",
      "metrics"
    ],
    "ground_truth_annotations": [
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        false,
        false,
        false
      ],
      "partial": [
        true,
        true,
        true,
        true,
        true
      ],
      "extra": [
        false,
        false,
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false,
        false
      ]
    },
    "notes": "This might be a case where the granularity of the Haiku components dilutes the retrieval results whereas combining them in a single sentence makes it easier to find because the gold context contains all components in a single sentence."
  },
  {
    "chapter": 4,
    "question_number": 34,
    "question_text": "\"What is \"ReLU\"? Draw a plot of it for values from -2 to +2.\"",
    "gold_standard_answer": "\"ReLU just means \u201creplace any negative numbers with zero\u201d. It is a commonly used activation function.\"",
    "ground_truth_components": [
      "\"ReLU just means \u201creplace any negative numbers with zero\u201d. It is a commonly used activation function.\""
    ],
    "haiku_components": [
      "\"ReLU just means \"replace any negative numbers with zero\"\"",
      "\"It is a commonly used activation function.\""
    ],
    "ground_truth_annotations": [
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false
      ],
      "partial": [
        true,
        true
      ],
      "extra": [
        false,
        false
      ],
      "hallucination": [
        false,
        false
      ]
    },
    "notes": "\"It is a commonly used activation function.\" might not have any retrieval hit as it might not be a phrase used in the text. potential TODO: remove that part from the answer components. Another scenario where Haiku's components are helping me improve the dataset."
  },
  {
    "chapter": 4,
    "question_number": 35,
    "question_text": "\"What is an \"activation function\"?\"",
    "gold_standard_answer": "\"The activation function is another function that is part of the neural network, which has the purpose of providing non-linearity to the model. The idea is that without an activation function, we just have multiple linear functions of the form y=mx+b. However, a series of linear layers is equivalent to a single linear layer, so our model can only fit a line to the data. By introducing a non-linearity in between the linear layers, this is no longer true. Each layer is somewhat decoupled from the rest of the layers, and the model can now fit much more complex functions. In fact, it can be mathematically proven that such a model can solve any computable problem to an arbitrarily high accuracy, if the model is large enough with the correct weights. This is known as the universal approximation theorem.\"",
    "ground_truth_components": [
      "The activation function is another function that is part of the neural network, which has the purpose of providing non-linearity to the model",
      "a series of linear layers is equivalent to a single linear layer, so our model can only fit a line to the data",
      "By introducing a non-linearity in between the linear layers, this is no longer true. Each layer is somewhat decoupled from the rest of the layers, and the model can now fit much more complex functions",
      "In fact, it can be mathematically proven that such a model can solve any computable problem to an arbitrarily high accuracy, if the model is large enough with the correct weights. This is known as the universal approximation theorem"
    ],
    "haiku_components": [
      "The activation function is another function that is part of the neural network, which has the purpose of providing non-linearity to the model.",
      "Without an activation function, we just have multiple linear functions of the form y=mx+b.",
      "A series of linear layers is equivalent to a single linear layer, so our model can only fit a line to the data.",
      "By introducing a non-linearity in between the linear layers, this is no longer true.",
      "Each layer is somewhat decoupled from the rest of the layers, and the model can now fit much more complex functions.",
      "It can be mathematically proven that such a model can solve any computable problem to an arbitrarily high accuracy, if the model is large enough with the correct weights.",
      "This is known as the universal approximation theorem."
    ],
    "ground_truth_annotations": [
      false,
      false,
      false,
      false
    ],
    "haiku_annotations": {
      "exact": [
        true,
        false,
        true,
        false,
        false,
        false,
        false
      ],
      "partial": [
        false,
        false,
        false,
        true,
        true,
        true,
        true
      ],
      "extra": [
        false,
        true,
        false,
        false,
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    "notes": "Potential TODO: add \"Without an activation function, we just have multiple linear functions of the form y=mx+b.\" to answer components.\n\nHaiku components \"By introducing a non-linearity in between the linear layers, this is no longer true.\" and \"Each layer is somewhat decoupled from the rest of the layers, and the model can now fit much more complex functions.\" correspond to separate sentences in the chapter text which \"okays\" the granularity imo currently. Same goes for \"It can be mathematically proven that such a model can solve any computable problem to an arbitrarily high accuracy, if the model is large enough with the correct weights.\" and \"This is known as the universal approximation theorem.\"."
  },
  {
    "chapter": 4,
    "question_number": 36,
    "question_text": "\"What's the difference between F.relu and nn.ReLU?\"",
    "gold_standard_answer": "\"F.relu is a Python function for the relu activation function. On the other hand, nn.ReLU is a PyTorch module. This means that it is a Python class that can be called as a function in the same way as F.relu.\"",
    "ground_truth_components": [
      "\"F.relu is a Python function for the relu activation function. On the other hand, nn.ReLU is a PyTorch module. This means that it is a Python class that can be called as a function in the same way as F.relu.\""
    ],
    "haiku_components": [
      "F.relu is a Python function for the relu activation function.",
      "nn.ReLU is a PyTorch module.",
      "nn.ReLU is a Python class that can be called as a function in the same way as F.relu."
    ],
    "ground_truth_annotations": [
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        false
      ],
      "partial": [
        true,
        true,
        true
      ],
      "extra": [
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        true
      ]
    },
    "notes": "Another example where Haiku component granularity best case yields redundant retrieval results and worst case are too granular to provide enough context. TBD."
  },
  {
    "chapter": 4,
    "question_number": 37,
    "question_text": "\"The universal approximation theorem shows that any function can be approximated as closely as needed using just one nonlinearity. So why do we normally use more?\"",
    "gold_standard_answer": "\"There are practical performance benefits to using more than one nonlinearity. We can use a deeper model with less number of parameters, better performance, faster training, and less compute/memory requirements.\"",
    "ground_truth_components": [
      "\"There are practical performance benefits to using more than one nonlinearity. We can use a deeper model with less number of parameters, better performance, faster training, and less compute/memory requirements.\""
    ],
    "haiku_components": [
      "There are practical performance benefits to using more than one nonlinearity.",
      "We can use a deeper model with less number of parameters",
      "better performance",
      "faster training",
      "less compute/memory requirements"
    ],
    "ground_truth_annotations": [
      false
    ],
    "haiku_annotations": {
      "exact": [
        false,
        false,
        false,
        false,
        false
      ],
      "partial": [
        true,
        true,
        true,
        true,
        true
      ],
      "extra": [
        false,
        false,
        false,
        false,
        false
      ],
      "hallucination": [
        false,
        false,
        false,
        false,
        false
      ]
    },
    "notes": "Haiku components \"better performance\", \"faster training\" and  \"less compute/memory requirements\" are too general and may dilute retrieval results. \n\nTODO: you could argue that \"There are practical performance benefits to using more than one nonlinearity.\" component is not explicitly found in the text whereas \"We can use a deeper model with less number of parameters\" is, but the former puts the latter into context. TBD on how they perform separately during retrieval."
  }
]